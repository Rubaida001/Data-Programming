{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the libraries \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas      as pd\n",
    "import numpy       as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eruba\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "#read the csv.file\n",
    "data = pd.read_csv(\"h1b_kaggle.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no of rows and columns in dataset\n",
    "print('No of rows and columns: ',data.shape)\n",
    "print('\\n Total no of entry in each column: \\n', data.count())\n",
    "\n",
    "#no of missing value\n",
    "print('\\n No of missing values: ')\n",
    "for col in cdf.columns:\n",
    "    print (col,cdf[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#made a deep copy of dataset\n",
    "cdf = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with missing values [each row with total 7 columns of NAN values]\n",
    "cdf = cdf.dropna(axis='rows', thresh=7)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1: CASE_STATUS\n",
    "cdf['CASE_STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge 'CERTIFIED-WITHDRAWN' value with 'CERTIFIED' \n",
    "cdf['CASE_STATUS'] = np.where(cdf['CASE_STATUS']=='CERTIFIED-WITHDRAWN','CERTIFIED',cdf['CASE_STATUS'])\n",
    "\n",
    "# drop rows with 'WITHDRAWN' value \n",
    "indexNames = cdf[cdf['CASE_STATUS']=='WITHDRAWN'].index\n",
    "cdf.drop(indexNames , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace 'CASE_STATUS' labels with numeric values from '1-6'\n",
    "cdf['CASE_STATUS'] = cdf['CASE_STATUS'].replace({'CERTIFIED': 1,'DENIED':2,'PENDING QUALITY AND COMPLIANCE REVIEW - UNASSIGNED':3,'REJECTED':4,'INVALIDATED':5}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 2: EMPLOYER_NAME\n",
    "#remove special characters to uniform format to get a better understanding of the dataset and enforce consistency. \n",
    "cdf['EMPLOYER_NAME']=cdf['EMPLOYER_NAME'].str.lower().replace(\"&QUOT;\",\"\")    \n",
    "cdf['EMPLOYER_NAME']=cdf['EMPLOYER_NAME'].str.replace(\"[.,)\\\"'&(+/]\",\"\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3: SOC_NAME\n",
    "#remove special characters to uniform format\n",
    "cdf['SOC_NAME']=cdf['SOC_NAME'].str.lower().replace(\"<FONT>|</FONT>|^[0-9]$\",\"\")\n",
    "\n",
    "#drop ambiguous values\n",
    "a = ['13-2011.01','15-1121','15-1132','15-1199.01','17-2051','27-3031']\n",
    "cdf = cdf[~cdf['SOC_NAME'].isin(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 4: JOB_TITLE\n",
    "#remove special characters to uniform format\n",
    "cdf['JOB_TITLE']=cdf['JOB_TITLE'].str.lower().replace(\"[.,)\\-]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf['JOB_TITLE'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 5: FULL_TIME_POSITION\n",
    "#replace 'Y' and 'N' label of 'FULL_TIME_POSITION' respectively with '1' and '0'\n",
    "cdf['FULL_TIME_POSITION']=cdf['FULL_TIME_POSITION'].replace({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 7: YEAR\n",
    "# convert year as integer type value\n",
    "cdf['YEAR'] = cdf['YEAR'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 8: WORKSITE\n",
    "#select state as employer location\n",
    "cdf['WORKSITE']=cdf['WORKSITE'].str.split(',',1).str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 8: lattitude and longitutde\n",
    "#drop lattitude and longitutde\n",
    "cdf.drop('lon',inplace=True,axis=1)\n",
    "cdf.drop('lat',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 companies with most application\n",
    "\n",
    "comp_counts = cdf['EMPLOYER_NAME'].value_counts().head(10)\n",
    "print(comp_counts)\n",
    "ax = comp_counts.plot.barh()\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('Top 10 Company with most applications')\n",
    "ax.set_xlabel('Frequency')\n",
    "ax.set_ylabel('Company Name')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total number of case file in each year\n",
    "cdf.groupby(['YEAR', 'CASE_STATUS']).size().unstack().plot(kind='bar', stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratio of application outcomes for each year\n",
    "pd.crosstab(cdf['YEAR'],cdf['CASE_STATUS']).apply(lambda r: r/r.sum()*100, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median wage:  65000.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    2.912587e+06\n",
       "mean     1.428912e+05\n",
       "std      5.282317e+06\n",
       "min      0.000000e+00\n",
       "25%      5.441300e+04\n",
       "50%      6.500000e+04\n",
       "75%      8.143200e+04\n",
       "max      6.997607e+09\n",
       "Name: PREVAILING_WAGE, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min, max and median wage \n",
    "median_wage = np.nanmedian(cdf[['PREVAILING_WAGE']])\n",
    "print('Median wage: ', median_wage)\n",
    "cdf[\"PREVAILING_WAGE\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of outliers:  113489\n"
     ]
    }
   ],
   "source": [
    "#detect outlier in PREVAILING_WAGE\n",
    "q1 = cdf[\"PREVAILING_WAGE\"].quantile(0.25)\n",
    "q3 = cdf[\"PREVAILING_WAGE\"].quantile(0.75)\n",
    "IQR = q3 - q1\n",
    "outliers = ((cdf[\"PREVAILING_WAGE\"] < (q1 - 1.5 * IQR)) | (cdf[\"PREVAILING_WAGE\"] > (q3 + 1.5 * IQR))).sum()\n",
    "print('No of outliers: ', outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace outlier with median value\n",
    "cdf[\"PREVAILING_WAGE\"] = cdf[\"PREVAILING_WAGE\"].mask(((cdf[\"PREVAILING_WAGE\"] < (q1 - 1.5 * IQR)) | (cdf[\"PREVAILING_WAGE\"] > (q3 + 1.5 * IQR))), median_wage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 10 preffered type of job \n",
    "job_counts = cdf['SOC_NAME'].value_counts().head(10)\n",
    "print(job_counts)\n",
    "\n",
    "#plot the findings\n",
    "ax = job_counts.plot.barh()\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('Top 10 prefferable job title')\n",
    "ax.set_xlabel('Frequency')\n",
    "ax.set_ylabel('Job Title')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 5 cities with most job opportunity\n",
    "\n",
    "cdf['WORKSITE'].value_counts().head(5).plot(kind='pie',startangle=90, autopct='%.1f%%')\n",
    "plt.title('Top 5 cities with most job opportunity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visa application success ratio based on job status\n",
    "table = pd.crosstab(cdf['CASE_STATUS'], cdf['FULL_TIME_POSITION'],\n",
    "margins=True)\n",
    "table = table.sort_values(by='All', ascending=False)\n",
    "table.drop('All', inplace=True)\n",
    "table.drop('All', axis='columns', inplace=True)\n",
    "ax = table.plot.barh()\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('Application status based on job status')\n",
    "ax.set_xlabel('Frequency')\n",
    "ax.set_ylabel('Application Status')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
